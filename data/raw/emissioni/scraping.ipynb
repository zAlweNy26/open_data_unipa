{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install beautifulsoup4 requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import csv\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# URL of the website to scrape\n",
    "url = 'https://en.wikipedia.org/wiki/European_emission_standards#Toxic_emission:_stages_and_legal_framework'\n",
    "\n",
    "# Send a GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content using BeautifulSoup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Find all the tables in the HTML content\n",
    "tables = soup.find_all('table')\n",
    "\n",
    "# Loop through each table and create a CSV file for it\n",
    "for i, table in enumerate(tables):\n",
    "    # Find the previous H3 heading for the table\n",
    "    prev_h3 = table.find_previous('h3')\n",
    "\n",
    "    # Find all the rows in the table\n",
    "    rows = table.find_all('tr')\n",
    "    \n",
    "    # Skip tables with less than 2 rows or without previous H3 heading\n",
    "    if len(rows) < 2 or prev_h3 is None:\n",
    "        continue\n",
    "    \n",
    "    # Use the text of the previous H3 heading as the filename\n",
    "    filename = prev_h3.get_text(strip=True).lower().replace('[edit]', '').replace(' ', '_')\n",
    "    \n",
    "    # Remove everything after the first '(' in the filename\n",
    "    filename = filename.split('(', 1)[0]\n",
    "\n",
    "    # Remove everything before the first '_' in the filename\n",
    "    filename = filename.split('_', 1)[-1]\n",
    "\n",
    "    # Add the \".csv\" extension to the filename\n",
    "    filename = f'{filename}.csv'\n",
    "\n",
    "    # Find the previous paragraph for the table\n",
    "    prev_par = table.find_previous('p').get_text(strip=True)\n",
    "\n",
    "    # Check if file already exists\n",
    "    if os.path.exists(filename) or ('Class II)' not in prev_par and 'light_commercial_vehicles' in filename):\n",
    "        continue\n",
    "    \n",
    "    # Open the CSV file in write mode with 'utf-8' encoding\n",
    "    with open(filename, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        # Create a CSV writer object\n",
    "        writer = csv.writer(csvfile)\n",
    "        \n",
    "        # Loop through each row and write it to the CSV file\n",
    "        for i, row in enumerate(rows):\n",
    "            # Find all the cells in the row\n",
    "            cells = row.find_all(['th', 'td'])\n",
    "\n",
    "            first_cell = cells[0].get_text(strip=True)\n",
    "            \n",
    "            # Skip if the first cell contains the text 'Euro', it's not the first row and has more then 1 cell\n",
    "            # Or if the first cell contains the text '^' in the first 2 characters\n",
    "            if ('Euro' not in first_cell and i != 0 and len(cells) > 1) or '^' in first_cell[:2]:\n",
    "                continue\n",
    "            \n",
    "            # Extract the text from each cell and write it to the CSV file\n",
    "            writer.writerow([cell.get_text(strip=True) for cell in cells])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
